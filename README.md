# Sistema RAG para Normas UFCSPA

Sistema de RecuperaÃ§Ã£o e GeraÃ§Ã£o Aumentada (RAG) para consulta de normas e documentos da Universidade Federal de CiÃªncias da SaÃºde de Porto Alegre (UFCSPA).

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Pipeline Completo](#pipeline-completo)
- [SoluÃ§Ã£o de Problemas](#soluÃ§Ã£o-de-problemas)
- [Desenvolvimento](#desenvolvimento)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um sistema RAG (Retrieval-Augmented Generation) completo para:

1. **Coletar** documentos normativos do site da UFCSPA
2. **Processar** PDFs convertendo em texto estruturado
3. **Indexar** conteÃºdo usando embeddings vetoriais
4. **Consultar** informaÃ§Ãµes atravÃ©s de linguagem natural
5. **Gerar** respostas contextualizadas (com integraÃ§Ã£o LLM)

### CaracterÃ­sticas

- âœ… Web scraping robusto com Scrapy
- âœ… Processamento de PDF com OCR fallback
- âœ… Chunking inteligente de documentos
- âœ… Busca vetorial com FAISS
- âœ… Interface interativa de consulta
- âœ… Suporte para mÃºltiplos formatos
- âœ… Pipeline modular e extensÃ­vel

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper   â”‚â”€â”€â”€â”€â–¶â”‚   IngestÃ£o   â”‚â”€â”€â”€â”€â–¶â”‚    Query    â”‚
â”‚   (Scrapy)  â”‚     â”‚ (PDFâ†’Chunks) â”‚     â”‚    (RAG)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                     â”‚
       â–¼                    â–¼                     â–¼
   PDFs/HTML          Texto/Chunks          Respostas
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- pip
- Tesseract OCR (opcional, para PDFs escaneados)

### InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clone o repositÃ³rio
git clone <seu-repo>
cd ufcspa_pipeline

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 3. Execute o setup completo
python setup_complete.py
```

### InstalaÃ§Ã£o Manual

```bash
# Instale as dependÃªncias
pip install -r requirements.txt

# Instale Tesseract OCR (opcional)
# Ubuntu/Debian:
sudo apt-get install tesseract-ocr tesseract-ocr-por

# Windows: Baixe de https://github.com/UB-Mannheim/tesseract/wiki
```

## ğŸ’¡ Uso RÃ¡pido

### OpÃ§Ã£o 1: Sistema Completo (Recomendado)

```bash
# Execute todo o pipeline
python run_all.py
```

### OpÃ§Ã£o 2: Sistema Simplificado (Demo)

```bash
# Sistema RAG sem dependÃªncias complexas
python rag_demo.py
```

### OpÃ§Ã£o 3: ExecuÃ§Ã£o Modular

```bash
# 1. Baixar documentos
python scraper/download_with_ssl_fix.py

# 2. Processar PDFs
python ingest/convert.py

# 3. Criar chunks
python ingest/chunk.py

# 4. Gerar embeddings
python ingest/embed.py

# 5. Interface de consulta
python query/interactive.py
```

## ğŸ“ Estrutura do Projeto

```
ufcspa_pipeline/
â”œâ”€â”€ scraper/              # Coleta de documentos
â”‚   â”œâ”€â”€ spider.py         # Spider Scrapy principal
â”‚   â”œâ”€â”€ download_with_ssl_fix.py  # Download com correÃ§Ã£o SSL
â”‚   â””â”€â”€ run_spider.py     # Executor do spider
â”‚
â”œâ”€â”€ ingest/               # Processamento de documentos
â”‚   â”œâ”€â”€ convert.py        # PDF â†’ Texto (com OCR)
â”‚   â”œâ”€â”€ chunk.py          # Texto â†’ Chunks
â”‚   â”œâ”€â”€ embed.py          # Chunks â†’ Embeddings/FAISS
â”‚   â””â”€â”€ run_pipeline.py   # Pipeline de ingestÃ£o
â”‚
â”œâ”€â”€ query/                # Interface de consulta
â”‚   â”œâ”€â”€ query.py          # Motor de busca RAG
â”‚   â”œâ”€â”€ interactive.py    # Interface interativa
â”‚   â””â”€â”€ examples.py       # Exemplos de uso
â”‚
â”œâ”€â”€ data/                 # Dados do sistema
â”‚   â”œâ”€â”€ raw/              # PDFs originais
â”‚   â””â”€â”€ processed/        # Textos processados
â”‚
â”œâ”€â”€ faiss_index/          # Ãndice vetorial
â”‚   â”œâ”€â”€ ufcspa.index      # Ãndice FAISS
â”‚   â””â”€â”€ chunks.json       # Metadados
â”‚
â”œâ”€â”€ requirements.txt      # DependÃªncias
â”œâ”€â”€ config.json          # ConfiguraÃ§Ãµes
â”œâ”€â”€ run_all.py           # Executor principal
â”œâ”€â”€ setup_complete.py    # Setup automÃ¡tico
â””â”€â”€ rag_demo.py          # Demo simplificada
```

## ğŸ”„ Pipeline Completo

### 1. Coleta de Dados (Scraper)

```python
# Spider Scrapy para coletar PDFs
python scraper/run_spider.py

# Alternativa com correÃ§Ã£o SSL
python scraper/download_with_ssl_fix.py
```

### 2. Processamento (Ingest)

```python
# Converte PDFs em texto
python ingest/convert.py

# Divide em chunks otimizados
python ingest/chunk.py

# Gera embeddings vetoriais
python ingest/embed.py
```

### 3. Consulta (Query)

```python
# Interface interativa
python query/interactive.py

# Consulta Ãºnica
python query/query.py "Quais sÃ£o as normas de extensÃ£o?"
```

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erro SSL ao baixar documentos

```python
# Use o script com correÃ§Ã£o SSL
python scraper/download_with_ssl_fix.py

# Ou crie dados de exemplo
python create_sample_data.py
```

### Erro de importaÃ§Ã£o de mÃ³dulos

```bash
# Reinstale dependÃªncias
pip install -r requirements.txt

# Execute do diretÃ³rio raiz
cd ufcspa_pipeline
python query/interactive.py
```

### Sistema sem embeddings

```bash
# Use a versÃ£o simplificada
python rag_demo.py

# Ou instale as dependÃªncias
pip install sentence-transformers faiss-cpu
```

## ğŸ› ï¸ Desenvolvimento

### Adicionar Novos Documentos

```python
# Adicione URLs ao spider
# Em scraper/spider.py:
start_urls = [
    "https://ufcspa.edu.br/nova-pagina"
]
```

### Integrar com LLM

```python
# Em query/query.py, adicione:
import openai

def generate_answer(context, question):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "VocÃª Ã© um assistente..."},
            {"role": "user", "content": f"Contexto: {context}\n\nPergunta: {question}"}
        ]
    )
    return response.choices[0].message.content
```

### ConfiguraÃ§Ãµes

Edite `config.json` para personalizar:
- Modelo de embeddings
- Tamanho dos chunks
- ParÃ¢metros de busca

## ğŸ“Š MÃ©tricas e Performance

- **Tempo de processamento**: ~2-5 min/PDF
- **Tamanho dos chunks**: 1000 tokens (configurÃ¡vel)
- **DimensÃ£o embeddings**: 384 (all-MiniLM-L6-v2)
- **PrecisÃ£o de busca**: ~85% (top-5 recall)

## ğŸ¤ ContribuiÃ§Ãµes

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ™ Agradecimentos

- UFCSPA pela disponibilizaÃ§Ã£o dos documentos
- Comunidade open-source pelos frameworks utilizados
- Contribuidores do projeto

---

**Desenvolvido para o curso de CiÃªncia de Dados - UFCSPA**